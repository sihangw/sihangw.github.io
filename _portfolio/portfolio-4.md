---
title: "Captioning Image to Assist People Who are Blind "
excerpt: "Leveraged attention-based deep learning model methods applied in image captioning areas."
collection: portfolio
---
Surveyed attention-based deep learning model methods applied in image captioning areas.

Implemented a model composed of Residual neural network (ResNet) and soft attention mechanism to generate high-level representative features. These features are then fed into a Long Short-Term Memory (LSTM) network to output a description of the image in valid English description.

Trained the model on VizWiz dataset with BLEU metric, the model achieved comparable to state-of-the-art performance and generated highly descriptive captions that can potentially greatly improve the lives of visually impaired people.


Report can be viewd [here](https://www.overleaf.com/read/ywxbkxwmdtbs) and slides can be viewed [here](https://docs.google.com/presentation/d/1zj5z99DbKDW8gAnEnNi9ozLESSbvrx3H/edit#slide=id.p1).

